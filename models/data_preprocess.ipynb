{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, utils\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, size=(224, 224)):\n",
    "    # Open and resize image\n",
    "    # image = Image.open(image_path)\n",
    "    image = image.resize(size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Convert the image to a numpy array and then to grayscale\n",
    "    img = np.array(image)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply a binary threshold to get a binary image\n",
    "    _, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "   # Check if contours list is not empty\n",
    "    if contours:\n",
    "        # Find the largest contour which should be the fundus\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Get the bounding rectangle for the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Crop the image to the bounding rectangle\n",
    "        cropped = image.crop((x, y, x+w, y+h))\n",
    "    else:\n",
    "        print(f\"No contours found in image\")\n",
    "        cropped = image  # or handle this case differently as per your requirement\n",
    "\n",
    "    # Resize the cropped image to the desired size\n",
    "    cropped = cropped.resize(size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # # Color normalization\n",
    "    # mean = np.mean(cropped, axis=(0, 1))\n",
    "    # image_normalized = cropped - mean\n",
    "\n",
    "    # Illumination correction and contrast enhancement using CLAHE\n",
    "    image_lab = cv2.cvtColor(np.uint8(cropped), cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(image_lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    image_clahe = cv2.merge((l_clahe, a, b))\n",
    "    image_clahe_rgb = cv2.cvtColor(image_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "\n",
    "    # Convert the image to uint8 before applying Gaussian blur\n",
    "    image_clahe_rgb_uint8 = (image_clahe_rgb * 255).astype(np.uint8)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    image_denoised = cv2.GaussianBlur(image_clahe_rgb_uint8, (5, 5), 0.5)\n",
    "\n",
    "    image_denoised = Image.fromarray(image_denoised)\n",
    "    return image_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_fundus_image(image_path, save_path=None):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a binary threshold to get a binary image\n",
    "    _, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour which should be the fundus\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Get the bounding rectangle for the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Crop the image to the bounding rectangle\n",
    "    cropped_img = img[y:y+h, x:x+w]\n",
    "    \n",
    "    # Save or return the cropped image\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, cropped_img)\n",
    "    else:\n",
    "        return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all_images(dataset_dirs=['DDR-dataset/DR_grading/train', 'DDR-dataset/DR_grading/valid', 'DDR-dataset/DR_grading/test']):\n",
    "    for dataset_dir in dataset_dirs:\n",
    "        image_files = os.listdir(dataset_dir)\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(dataset_dir, image_file)\n",
    "            image = Image.open(image_path)\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "            save_path = os.path.join(dataset_dir + '_preprocessed', image_file)\n",
    "            preprocessed_image.save(save_path)\n",
    "\n",
    "# preprocess_all_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('DDR-dataset/DR_grading/train.txt', sep=' ', header=None, names=['image', 'label'])\n",
    "train_df = train_df.query('label != 5')\n",
    "train_df['path'] = train_df['image'].apply(lambda x: os.path.join('DDR-dataset/DR_grading/train_preprocessed', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(df):\n",
    "    new_rows = []\n",
    "    class_counts = np.bincount(df['label'])\n",
    "    difference = np.max(class_counts) - class_counts\n",
    "    aug_transforms = v2.Compose([\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.RandomVerticalFlip(p=0.5),\n",
    "        v2.RandomRotation(degrees=360),\n",
    "        v2.RandomPerspective(distortion_scale=0, p=1, interpolation=3),\n",
    "        v2.RandomAffine(degrees=0, translate=(0, 0), scale=(1, 1), shear=0),\n",
    "        v2.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "    ])\n",
    "    for i, count in enumerate(difference):\n",
    "        if count > 0:\n",
    "            samples = df.query(f'label == {i}').sample(count, replace=True)\n",
    "            # print(len(samples))\n",
    "            for index, row in samples.iterrows():\n",
    "                image = Image.open(row['path'])\n",
    "                augmented_image = aug_transforms(image)\n",
    "                augmented_image.save(f'{row[\"path\"][:-4]}_augmented{count}.png')\n",
    "                new_rows.append({'image': f'{row[\"image\"][:-4]}_augmented{count}.png', 'label': i, 'path': f'{row[\"path\"][:-4]}_augmented{count}.png'})\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    new_df = pd.concat([df, new_df])\n",
    "    return new_df\n",
    "\n",
    "# new_df = balance_dataset(train_df)\n",
    "\n",
    "# new_df.to_csv('DDR-dataset/DR_grading/train_augmented.txt', sep=' ', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
